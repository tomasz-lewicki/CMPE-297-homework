{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import imgaug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "from coco.coco import CocoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COCO_PRETRAINED_WEIGHTS_PATH = os.path.abspath(\"mask_rcnn_coco.h5\")\n",
    "DATASET_PATH = os.path.abspath(\"DATASETS/\")\n",
    "TRAIN_ANNOTATIONS_PATH = os.path.abspath(\"DATASETS/annotations/instances_train2017.json\")\n",
    "LOGS_PATH = os.path.abspath(\"LOGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoConfig(Config):\n",
    "    \"\"\"Configuration for training on MS COCO.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the COCO dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"coco\"\n",
    "    \n",
    "    IMAGES_PER_GPU = 2 \n",
    "    #the model fits only once on my 6GB GTX1060. \n",
    "    #fits twice on 12GB Tesla P100\n",
    "    \n",
    "    NUM_CLASSES = 1 + 80  #80 COCO classes + BG class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.50s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train_annotatons = COCO(TRAIN_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.22s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#Train dataset\n",
    "dataset_train = CocoDataset()\n",
    "dataset_train.load_coco(dataset_dir=DATASET_PATH, subset=\"train\", year=2017, class_ids=None,\n",
    "                        class_map=None, return_coco=False, auto_download=False)\n",
    "dataset_train.prepare()\n",
    "\n",
    "\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = CocoDataset()\n",
    "dataset_val.load_coco(dataset_dir=DATASET_PATH, subset=\"val\", year=2017, auto_download=False)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING with, LR: 0.005, DECAY: 0.0001\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.005\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190414T2128/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/013855803/anaconda3/envs/mrcnn/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/013855803/anaconda3/envs/mrcnn/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 920s 920ms/step - loss: 4.5900 - rpn_class_loss: 0.3284 - rpn_bbox_loss: 2.0248 - mrcnn_class_loss: 0.3366 - mrcnn_bbox_loss: 1.2904 - mrcnn_mask_loss: 0.6098 - val_loss: 3.3015 - val_rpn_class_loss: 0.2262 - val_rpn_bbox_loss: 0.6835 - val_mrcnn_class_loss: 0.5708 - val_mrcnn_bbox_loss: 1.0297 - val_mrcnn_mask_loss: 0.7913\n",
      "Fine tune Resnet stage 4 and up\n",
      "\n",
      "Starting at epoch 1. LR=0.005\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190414T2128/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 2/8\n",
      "1000/1000 [==============================] - 1114s 1s/step - loss: 1.7334 - rpn_class_loss: 0.1043 - rpn_bbox_loss: 0.4313 - mrcnn_class_loss: 0.2919 - mrcnn_bbox_loss: 0.3675 - mrcnn_mask_loss: 0.5384 - val_loss: 4.7139 - val_rpn_class_loss: 0.4523 - val_rpn_bbox_loss: 1.3772 - val_mrcnn_class_loss: 1.1997 - val_mrcnn_bbox_loss: 0.7418 - val_mrcnn_mask_loss: 0.9429\n",
      "Epoch 3/8\n",
      "1000/1000 [==============================] - 991s 991ms/step - loss: 1.5390 - rpn_class_loss: 0.0979 - rpn_bbox_loss: 0.4422 - mrcnn_class_loss: 0.2174 - mrcnn_bbox_loss: 0.3088 - mrcnn_mask_loss: 0.4727 - val_loss: 11.0178 - val_rpn_class_loss: 2.1773 - val_rpn_bbox_loss: 6.8561 - val_mrcnn_class_loss: 0.1034 - val_mrcnn_bbox_loss: 1.0236 - val_mrcnn_mask_loss: 0.8573\n",
      "Epoch 4/8\n",
      "1000/1000 [==============================] - 1113s 1s/step - loss: 1.5684 - rpn_class_loss: 0.1119 - rpn_bbox_loss: 0.4239 - mrcnn_class_loss: 0.2539 - mrcnn_bbox_loss: 0.3231 - mrcnn_mask_loss: 0.4556 - val_loss: 8.6690 - val_rpn_class_loss: 1.0267 - val_rpn_bbox_loss: 4.1532 - val_mrcnn_class_loss: 1.3835 - val_mrcnn_bbox_loss: 0.9376 - val_mrcnn_mask_loss: 1.1680\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1007s 1s/step - loss: 1.5365 - rpn_class_loss: 0.0746 - rpn_bbox_loss: 0.4550 - mrcnn_class_loss: 0.2620 - mrcnn_bbox_loss: 0.3081 - mrcnn_mask_loss: 0.4368 - val_loss: 10.6945 - val_rpn_class_loss: 2.2953 - val_rpn_bbox_loss: 5.9308 - val_mrcnn_class_loss: 0.9392 - val_mrcnn_bbox_loss: 0.8333 - val_mrcnn_mask_loss: 0.6959\n",
      "Epoch 6/8\n",
      "1000/1000 [==============================] - 950s 950ms/step - loss: 1.6056 - rpn_class_loss: 0.0972 - rpn_bbox_loss: 0.5533 - mrcnn_class_loss: 0.2491 - mrcnn_bbox_loss: 0.2897 - mrcnn_mask_loss: 0.4162 - val_loss: 6.2839 - val_rpn_class_loss: 1.0811 - val_rpn_bbox_loss: 2.8756 - val_mrcnn_class_loss: 0.7750 - val_mrcnn_bbox_loss: 0.6709 - val_mrcnn_mask_loss: 0.8813\n",
      "Epoch 7/8\n",
      "1000/1000 [==============================] - 985s 985ms/step - loss: 1.5254 - rpn_class_loss: 0.0714 - rpn_bbox_loss: 0.5502 - mrcnn_class_loss: 0.2300 - mrcnn_bbox_loss: 0.2786 - mrcnn_mask_loss: 0.3953 - val_loss: 10.9554 - val_rpn_class_loss: 2.4994 - val_rpn_bbox_loss: 6.3951 - val_mrcnn_class_loss: 0.5118 - val_mrcnn_bbox_loss: 0.6226 - val_mrcnn_mask_loss: 0.9265\n",
      "Epoch 8/8\n",
      "1000/1000 [==============================] - 929s 929ms/step - loss: 1.5707 - rpn_class_loss: 0.0830 - rpn_bbox_loss: 0.6148 - mrcnn_class_loss: 0.2303 - mrcnn_bbox_loss: 0.2754 - mrcnn_mask_loss: 0.3672 - val_loss: 14.0553 - val_rpn_class_loss: 3.3597 - val_rpn_bbox_loss: 8.8886 - val_mrcnn_class_loss: 0.5480 - val_mrcnn_bbox_loss: 0.5901 - val_mrcnn_mask_loss: 0.6688\n",
      "Epoch 2/8TRAINING with, LR: 0.003775, DECAY: 0.0001\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.003775\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190414T2344/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 1004s 1s/step - loss: 3.2504 - rpn_class_loss: 0.2786 - rpn_bbox_loss: 1.2356 - mrcnn_class_loss: 0.3120 - mrcnn_bbox_loss: 0.7930 - mrcnn_mask_loss: 0.6312 - val_loss: 7.8247 - val_rpn_class_loss: 3.1401 - val_rpn_bbox_loss: 3.2330 - val_mrcnn_class_loss: 0.1490 - val_mrcnn_bbox_loss: 0.6300 - val_mrcnn_mask_loss: 0.6726\n",
      "Fine tune Resnet stage 4 and up\n",
      "\n",
      "Starting at epoch 1. LR=0.003775\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190414T2344/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 2/8\n",
      "1000/1000 [==============================] - 1118s 1s/step - loss: 1.7180 - rpn_class_loss: 0.0972 - rpn_bbox_loss: 0.3283 - mrcnn_class_loss: 0.3350 - mrcnn_bbox_loss: 0.3999 - mrcnn_mask_loss: 0.5577 - val_loss: 6.9504 - val_rpn_class_loss: 3.0794 - val_rpn_bbox_loss: 2.4619 - val_mrcnn_class_loss: 0.1013 - val_mrcnn_bbox_loss: 0.4860 - val_mrcnn_mask_loss: 0.8218\n",
      "Epoch 3/8\n",
      "1000/1000 [==============================] - 983s 983ms/step - loss: 1.7053 - rpn_class_loss: 0.0977 - rpn_bbox_loss: 0.5185 - mrcnn_class_loss: 0.2642 - mrcnn_bbox_loss: 0.3210 - mrcnn_mask_loss: 0.5040 - val_loss: 10.4457 - val_rpn_class_loss: 1.5214 - val_rpn_bbox_loss: 5.1642 - val_mrcnn_class_loss: 0.6075 - val_mrcnn_bbox_loss: 1.0174 - val_mrcnn_mask_loss: 2.1352\n",
      "Epoch 4/8\n",
      "1000/1000 [==============================] - 942s 942ms/step - loss: 1.4960 - rpn_class_loss: 0.0669 - rpn_bbox_loss: 0.3791 - mrcnn_class_loss: 0.2632 - mrcnn_bbox_loss: 0.3069 - mrcnn_mask_loss: 0.4799 - val_loss: 4.3956 - val_rpn_class_loss: 0.3662 - val_rpn_bbox_loss: 1.9242 - val_mrcnn_class_loss: 0.7526 - val_mrcnn_bbox_loss: 0.7226 - val_mrcnn_mask_loss: 0.6300\n",
      "Epoch 5/8\n",
      "1000/1000 [==============================] - 1012s 1s/step - loss: 1.5286 - rpn_class_loss: 0.0812 - rpn_bbox_loss: 0.4411 - mrcnn_class_loss: 0.2419 - mrcnn_bbox_loss: 0.3051 - mrcnn_mask_loss: 0.4594 - val_loss: 4.4603 - val_rpn_class_loss: 0.8341 - val_rpn_bbox_loss: 1.5933 - val_mrcnn_class_loss: 0.1986 - val_mrcnn_bbox_loss: 0.7668 - val_mrcnn_mask_loss: 1.0675\n",
      "Epoch 6/8\n",
      "1000/1000 [==============================] - 1049s 1s/step - loss: 1.5649 - rpn_class_loss: 0.0612 - rpn_bbox_loss: 0.4523 - mrcnn_class_loss: 0.2947 - mrcnn_bbox_loss: 0.3157 - mrcnn_mask_loss: 0.4410 - val_loss: 13.5919 - val_rpn_class_loss: 2.2971 - val_rpn_bbox_loss: 8.4909 - val_mrcnn_class_loss: 1.0532 - val_mrcnn_bbox_loss: 0.7192 - val_mrcnn_mask_loss: 1.0315\n",
      "Epoch 7/8\n",
      "1000/1000 [==============================] - 957s 957ms/step - loss: 1.6208 - rpn_class_loss: 0.0719 - rpn_bbox_loss: 0.5578 - mrcnn_class_loss: 0.2821 - mrcnn_bbox_loss: 0.2943 - mrcnn_mask_loss: 0.4147 - val_loss: 6.2994 - val_rpn_class_loss: 0.5623 - val_rpn_bbox_loss: 3.4168 - val_mrcnn_class_loss: 0.8635 - val_mrcnn_bbox_loss: 0.6745 - val_mrcnn_mask_loss: 0.7824\n",
      "Epoch 8/8\n",
      "1000/1000 [==============================] - 1139s 1s/step - loss: 1.5177 - rpn_class_loss: 0.0799 - rpn_bbox_loss: 0.4402 - mrcnn_class_loss: 0.2732 - mrcnn_bbox_loss: 0.3102 - mrcnn_mask_loss: 0.4142 - val_loss: 16.5680 - val_rpn_class_loss: 3.5158 - val_rpn_bbox_loss: 10.3090 - val_mrcnn_class_loss: 0.7960 - val_mrcnn_bbox_loss: 0.8404 - val_mrcnn_mask_loss: 1.1068\n",
      "TRAINING with, LR: 0.00255, DECAY: 0.0001\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.00255\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190415T0203/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 1096s 1s/step - loss: 3.2739 - rpn_class_loss: 0.2290 - rpn_bbox_loss: 1.3143 - mrcnn_class_loss: 0.2731 - mrcnn_bbox_loss: 0.8137 - mrcnn_mask_loss: 0.6438 - val_loss: 4.6442 - val_rpn_class_loss: 1.2798 - val_rpn_bbox_loss: 1.2716 - val_mrcnn_class_loss: 0.3060 - val_mrcnn_bbox_loss: 1.0445 - val_mrcnn_mask_loss: 0.7423\n",
      "\n",
      "Fine tune Resnet stage 4 and up\n",
      "\n",
      "Starting at epoch 1. LR=0.00255\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190415T0203/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8\n",
      "1000/1000 [==============================] - 1246s 1s/step - loss: 1.5612 - rpn_class_loss: 0.0857 - rpn_bbox_loss: 0.3724 - mrcnn_class_loss: 0.2312 - mrcnn_bbox_loss: 0.3393 - mrcnn_mask_loss: 0.5327 - val_loss: 6.3979 - val_rpn_class_loss: 2.4018 - val_rpn_bbox_loss: 1.4773 - val_mrcnn_class_loss: 0.3784 - val_mrcnn_bbox_loss: 1.0831 - val_mrcnn_mask_loss: 1.0573\n",
      "Epoch 3/8\n",
      "1000/1000 [==============================] - 1099s 1s/step - loss: 1.7147 - rpn_class_loss: 0.1139 - rpn_bbox_loss: 0.4340 - mrcnn_class_loss: 0.2988 - mrcnn_bbox_loss: 0.3266 - mrcnn_mask_loss: 0.5414 - val_loss: 4.9885 - val_rpn_class_loss: 1.3135 - val_rpn_bbox_loss: 1.3587 - val_mrcnn_class_loss: 0.6097 - val_mrcnn_bbox_loss: 0.9641 - val_mrcnn_mask_loss: 0.7425\n",
      "Epoch 4/8\n",
      "1000/1000 [==============================] - 1047s 1s/step - loss: 1.3042 - rpn_class_loss: 0.0532 - rpn_bbox_loss: 0.2216 - mrcnn_class_loss: 0.2523 - mrcnn_bbox_loss: 0.2829 - mrcnn_mask_loss: 0.4943 - val_loss: 8.2357 - val_rpn_class_loss: 3.1749 - val_rpn_bbox_loss: 2.5564 - val_mrcnn_class_loss: 0.7275 - val_mrcnn_bbox_loss: 0.8681 - val_mrcnn_mask_loss: 0.9088\n",
      "Epoch 5/8\n",
      "1000/1000 [==============================] - 942s 942ms/step - loss: 1.2247 - rpn_class_loss: 0.0492 - rpn_bbox_loss: 0.2971 - mrcnn_class_loss: 0.1940 - mrcnn_bbox_loss: 0.2565 - mrcnn_mask_loss: 0.4279 - val_loss: 4.1748 - val_rpn_class_loss: 0.6896 - val_rpn_bbox_loss: 1.3801 - val_mrcnn_class_loss: 0.4020 - val_mrcnn_bbox_loss: 0.7724 - val_mrcnn_mask_loss: 0.9307\n",
      "Epoch 6/8\n",
      "1000/1000 [==============================] - 957s 957ms/step - loss: 1.2518 - rpn_class_loss: 0.0527 - rpn_bbox_loss: 0.3005 - mrcnn_class_loss: 0.2309 - mrcnn_bbox_loss: 0.2451 - mrcnn_mask_loss: 0.4226 - val_loss: 4.4623 - val_rpn_class_loss: 0.3852 - val_rpn_bbox_loss: 1.9886 - val_mrcnn_class_loss: 0.4377 - val_mrcnn_bbox_loss: 0.6947 - val_mrcnn_mask_loss: 0.9561\n",
      "Epoch 7/8\n",
      "1000/1000 [==============================] - 950s 950ms/step - loss: 1.2139 - rpn_class_loss: 0.0532 - rpn_bbox_loss: 0.2964 - mrcnn_class_loss: 0.1970 - mrcnn_bbox_loss: 0.2420 - mrcnn_mask_loss: 0.4253 - val_loss: 9.1110 - val_rpn_class_loss: 1.6607 - val_rpn_bbox_loss: 4.3618 - val_mrcnn_class_loss: 0.9101 - val_mrcnn_bbox_loss: 0.9253 - val_mrcnn_mask_loss: 1.2530\n",
      "Epoch 8/8\n",
      "1000/1000 [==============================] - 1011s 1s/step - loss: 1.2340 - rpn_class_loss: 0.0439 - rpn_bbox_loss: 0.2899 - mrcnn_class_loss: 0.2358 - mrcnn_bbox_loss: 0.2597 - mrcnn_mask_loss: 0.4047 - val_loss: 10.3215 - val_rpn_class_loss: 1.5272 - val_rpn_bbox_loss: 5.8792 - val_mrcnn_class_loss: 1.3264 - val_mrcnn_bbox_loss: 0.8456 - val_mrcnn_mask_loss: 0.7431\n",
      "TRAINING with, LR: 0.0013250000000000002, DECAY: 0.0001\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.0013250000000000002\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190415T0426/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 1084s 1s/step - loss: 4.4496 - rpn_class_loss: 0.3877 - rpn_bbox_loss: 1.9666 - mrcnn_class_loss: 0.3787 - mrcnn_bbox_loss: 1.0351 - mrcnn_mask_loss: 0.6815 - val_loss: 5.1297 - val_rpn_class_loss: 0.5329 - val_rpn_bbox_loss: 2.2363 - val_mrcnn_class_loss: 0.7158 - val_mrcnn_bbox_loss: 0.9830 - val_mrcnn_mask_loss: 0.6616\n",
      "Fine tune Resnet stage 4 and up\n",
      "\n",
      "Starting at epoch 1. LR=0.0013250000000000002\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190415T0426/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8\n",
      "1000/1000 [==============================] - 1246s 1s/step - loss: 1.8395 - rpn_class_loss: 0.0963 - rpn_bbox_loss: 0.3757 - mrcnn_class_loss: 0.3376 - mrcnn_bbox_loss: 0.4026 - mrcnn_mask_loss: 0.6273 - val_loss: 5.8401 - val_rpn_class_loss: 0.7104 - val_rpn_bbox_loss: 2.6641 - val_mrcnn_class_loss: 0.9529 - val_mrcnn_bbox_loss: 0.8610 - val_mrcnn_mask_loss: 0.6518\n",
      "Epoch 3/8\n",
      "1000/1000 [==============================] - 966s 966ms/step - loss: 1.7604 - rpn_class_loss: 0.0707 - rpn_bbox_loss: 0.3989 - mrcnn_class_loss: 0.3295 - mrcnn_bbox_loss: 0.3643 - mrcnn_mask_loss: 0.5970 - val_loss: 5.1744 - val_rpn_class_loss: 0.2722 - val_rpn_bbox_loss: 1.3483 - val_mrcnn_class_loss: 1.6440 - val_mrcnn_bbox_loss: 1.0897 - val_mrcnn_mask_loss: 0.8202\n",
      "Epoch 4/8\n",
      "1000/1000 [==============================] - 1013s 1s/step - loss: 1.6351 - rpn_class_loss: 0.0809 - rpn_bbox_loss: 0.3940 - mrcnn_class_loss: 0.2754 - mrcnn_bbox_loss: 0.3187 - mrcnn_mask_loss: 0.5661 - val_loss: 3.5402 - val_rpn_class_loss: 0.1953 - val_rpn_bbox_loss: 1.0964 - val_mrcnn_class_loss: 0.6953 - val_mrcnn_bbox_loss: 0.8281 - val_mrcnn_mask_loss: 0.7251\n",
      "Epoch 5/8\n",
      "1000/1000 [==============================] - 1020s 1s/step - loss: 1.5164 - rpn_class_loss: 0.0549 - rpn_bbox_loss: 0.3202 - mrcnn_class_loss: 0.2642 - mrcnn_bbox_loss: 0.3088 - mrcnn_mask_loss: 0.5683 - val_loss: 5.3474 - val_rpn_class_loss: 1.1055 - val_rpn_bbox_loss: 1.9311 - val_mrcnn_class_loss: 0.6546 - val_mrcnn_bbox_loss: 1.0267 - val_mrcnn_mask_loss: 0.6295\n",
      "Epoch 6/8\n",
      "1000/1000 [==============================] - 961s 961ms/step - loss: 1.5005 - rpn_class_loss: 0.0588 - rpn_bbox_loss: 0.3278 - mrcnn_class_loss: 0.2603 - mrcnn_bbox_loss: 0.3022 - mrcnn_mask_loss: 0.5514 - val_loss: 4.3482 - val_rpn_class_loss: 0.7569 - val_rpn_bbox_loss: 1.4779 - val_mrcnn_class_loss: 0.4596 - val_mrcnn_bbox_loss: 0.9696 - val_mrcnn_mask_loss: 0.6842\n",
      "Epoch 7/8\n",
      "1000/1000 [==============================] - 962s 962ms/step - loss: 1.4021 - rpn_class_loss: 0.0455 - rpn_bbox_loss: 0.3477 - mrcnn_class_loss: 0.2094 - mrcnn_bbox_loss: 0.2846 - mrcnn_mask_loss: 0.5149 - val_loss: 5.4507 - val_rpn_class_loss: 0.6521 - val_rpn_bbox_loss: 1.9211 - val_mrcnn_class_loss: 0.7992 - val_mrcnn_bbox_loss: 0.9104 - val_mrcnn_mask_loss: 1.1678\n",
      "Epoch 8/8\n",
      "1000/1000 [==============================] - 1019s 1s/step - loss: 1.4471 - rpn_class_loss: 0.0779 - rpn_bbox_loss: 0.3861 - mrcnn_class_loss: 0.2149 - mrcnn_bbox_loss: 0.2934 - mrcnn_mask_loss: 0.4748 - val_loss: 6.7527 - val_rpn_class_loss: 1.0453 - val_rpn_bbox_loss: 2.3560 - val_mrcnn_class_loss: 0.6161 - val_mrcnn_bbox_loss: 0.8581 - val_mrcnn_mask_loss: 1.8772\n",
      "Epoch 2/8\n",
      "TRAINING with, LR: 0.0001, DECAY: 0.0001\n",
      "Epoch 2/8Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.0001\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190415T0649/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 1043s 1s/step - loss: 6.4720 - rpn_class_loss: 0.8844 - rpn_bbox_loss: 2.7907 - mrcnn_class_loss: 0.3969 - mrcnn_bbox_loss: 1.5779 - mrcnn_mask_loss: 0.8222 - val_loss: 9.6818 - val_rpn_class_loss: 2.0347 - val_rpn_bbox_loss: 4.8220 - val_mrcnn_class_loss: 0.6433 - val_mrcnn_bbox_loss: 1.4573 - val_mrcnn_mask_loss: 0.7244\n",
      "Fine tune Resnet stage 4 and up\n",
      "\n",
      "Starting at epoch 1. LR=0.0001\n",
      "\n",
      "Checkpoint Path: /home/013855803/CMPE-297-homework/LOGS/coco20190415T0649/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[400,256,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_9/SGD/gradients/mrcnn_mask_4/convolution_grad/Conv2DBackpropInput}} = Conv2DBackpropInput[T=DT_FLOAT, _class=[\"loc:@train...propFilter\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_9/SGD/gradients/mrcnn_mask_4/convolution_grad/Conv2DBackpropInput-0-VecPermuteNHWCToNCHW-LayoutOptimizer, mrcnn_mask_4/kernel/read, training_9/SGD/gradients/mrcnn_mask_4/Sigmoid_grad/SigmoidGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node training_9/SGD/gradients/mrcnn_mask_conv1_4/convolution_grad/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer/_23773}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_10615...tOptimizer\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-69d3e5982561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'4+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 augmentation=augmentation)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#     # Training - Stage 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CMPE-297-homework/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mrcnn/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mrcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mrcnn/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mrcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mrcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mrcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mrcnn/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[400,256,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_9/SGD/gradients/mrcnn_mask_4/convolution_grad/Conv2DBackpropInput}} = Conv2DBackpropInput[T=DT_FLOAT, _class=[\"loc:@train...propFilter\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_9/SGD/gradients/mrcnn_mask_4/convolution_grad/Conv2DBackpropInput-0-VecPermuteNHWCToNCHW-LayoutOptimizer, mrcnn_mask_4/kernel/read, training_9/SGD/gradients/mrcnn_mask_4/Sigmoid_grad/SigmoidGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node training_9/SGD/gradients/mrcnn_mask_conv1_4/convolution_grad/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer/_23773}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_10615...tOptimizer\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "\n",
    "LEARNING_RATES = np.linspace(0.005, 0.0001, 5)\n",
    "np.append(LEARNING_RATES, 0.02) #add the original learning rate from the paper\n",
    "\n",
    "histories = []\n",
    "\n",
    "for lr in LEARNING_RATES:\n",
    "    \n",
    "    config = CocoConfig()\n",
    "\n",
    "    config.LEARNING_RATE = lr\n",
    "    #config.LEARNING_RATE = 0.0025\n",
    "    config.LEARNING_MOMENTUM = 0.9\n",
    "\n",
    "    # Weight decay regularization\n",
    "    config.WEIGHT_DECAY = 0.0001\n",
    "    \n",
    "    print(\"TRAINING with, LR: {}, DECAY: {}\".format(config.LEARNING_RATE, config.WEIGHT_DECAY))\n",
    "    \n",
    "    # Create model\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=LOGS_PATH)\n",
    "        \n",
    "    # Training - Stage 1\n",
    "    print(\"Training network heads\")\n",
    "    hist1 = model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=1,\n",
    "                layers='heads',\n",
    "                augmentation=augmentation)\n",
    "\n",
    "    # Training - Stage 2\n",
    "    # Finetune layers from ResNet stage 4 and up\n",
    "    print(\"Fine tune Resnet stage 4 and up\")\n",
    "    hist2 = model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=8,\n",
    "                layers='4+',\n",
    "                augmentation=augmentation)\n",
    "\n",
    "#     # Training - Stage 3\n",
    "#     # Fine tune all layers\n",
    "#     print(\"Fine tune all layers\")\n",
    "#     hist3 = model.train(dataset_train, dataset_val,\n",
    "#                 learning_rate=config.LEARNING_RATE / 5,\n",
    "#                 epochs=1,\n",
    "#                 layers='all',\n",
    "#                 augmentation=augmentation)\n",
    "\n",
    "    histories.append({'hist1': hist1, 'hist2': hist2, 'lr': config.LEARNING_RATE, 'decay': config.WEIGHT_DECAY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': [9.681787357330322],\n",
       " 'val_rpn_class_loss': [2.0347118377685547],\n",
       " 'val_rpn_bbox_loss': [4.822039604187012],\n",
       " 'val_mrcnn_class_loss': [0.6433077299594879],\n",
       " 'val_mrcnn_bbox_loss': [1.4572844099998474],\n",
       " 'val_mrcnn_mask_loss': [0.7244408845901489],\n",
       " 'loss': [6.472034297227859],\n",
       " 'rpn_class_loss': [0.8843967587873339],\n",
       " 'rpn_bbox_loss': [2.7907462072372438],\n",
       " 'mrcnn_class_loss': [0.39686923583914724],\n",
       " 'mrcnn_bbox_loss': [1.5778649539649487],\n",
       " 'mrcnn_mask_loss': [0.8221539486646652]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for h in histories:\n",
    "    plt.plot(h['hist2'].history['loss'], label=h['lr'])\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "    \n",
    "plt.show()\n",
    "hist2.history\n",
    "hist1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
