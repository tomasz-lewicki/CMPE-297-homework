{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import imgaug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "from coco.coco import CocoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_PRETRAINED_WEIGHTS_PATH = os.path.abspath(\"mask_rcnn_coco.h5\")\n",
    "DATASET_PATH = os.path.abspath(\"DATASETS/\")\n",
    "TRAIN_ANNOTATIONS_PATH = os.path.abspath(\"DATASETS/annotations/instances_train2017.json\")\n",
    "LOGS_PATH = os.path.abspath(\"LOGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoConfig(Config):\n",
    "    \"\"\"Configuration for training on MS COCO.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the COCO dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"coco\"\n",
    "    \n",
    "    IMAGES_PER_GPU = 1 #Only one image fits on my 6GB GTX1060. \n",
    "    #IMAGES_PER_GPU = 1 #version for Tesla P100\n",
    "    \n",
    "    NUM_CLASSES = 1 + 80  #80 COCO classes + BG class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=18.61s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train_annotatons = COCO(TRAIN_ANNOTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=18.46s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.52s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#Train dataset\n",
    "dataset_train = CocoDataset()\n",
    "dataset_train.load_coco(dataset_dir=DATASET_PATH, subset=\"train\", year=2017, class_ids=None,\n",
    "                        class_map=None, return_coco=False, auto_download=False)\n",
    "dataset_train.prepare()\n",
    "\n",
    "\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = CocoDataset()\n",
    "dataset_val.load_coco(dataset_dir=DATASET_PATH, subset=\"val\", year=2017, auto_download=False)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/tomek/mask-rcnn-homework/LOGS/coco20190406T2034/mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/tomek/.local/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tomek/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 666, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"/home/tomek/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 661, in <lambda>\n",
      "    initargs=(seqs, self.random_seed))\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/tomek/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 666, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"/home/tomek/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 661, in <lambda>\n",
      "    initargs=(seqs, self.random_seed))\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/tomek/anaconda3/envs/mask-rcnn/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "config = CocoConfig()\n",
    "\n",
    "config.LEARNING_RATE = 0.001\n",
    "config.LEARNING_MOMENTUM = 0.9\n",
    "\n",
    "# Weight decay regularization\n",
    "config.WEIGHT_DECAY = 0.0001\n",
    "\n",
    "# Create model\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=LOGS_PATH)\n",
    "\n",
    "# Training - Stage 1\n",
    "print(\"Training network heads\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=1,\n",
    "            layers='heads',\n",
    "            augmentation=augmentation)\n",
    "\n",
    "# Training - Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "print(\"Fine tune Resnet stage 4 and up\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=120,\n",
    "            layers='4+',\n",
    "            augmentation=augmentation)\n",
    "\n",
    "# Training - Stage 3\n",
    "# Fine tune all layers\n",
    "print(\"Fine tune all layers\")\n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=160,\n",
    "            layers='all',\n",
    "            augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=args.logs)\n",
    "\n",
    "# model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "#                           model_dir=args.logs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
